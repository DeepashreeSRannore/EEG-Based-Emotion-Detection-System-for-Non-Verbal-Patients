# EEG-Based-Emotion-Detection-System-for-Non-Verbal-Patients
This project proposes a machine learning system that uses EEG brain signals to detect and classify emotions in non-verbal patients. The system performs multi-class
emotion classification using the DEAP dataset, employing a multi-scale dynamic CNN with gated transformer architecture. By categorizing emotional states into four classes
based on valence and arousal dimensions, the system aims to provide healthcare professionals with real-time, granular insights into patients’ emotional states, significantly
improving care for individuals with locked-in syndrome, severe paralysis, and related conditions.

## Architecture:
The proposed architecture integrates a multi-scale dynamic CNN for spatial feature extraction, a gated transformer for temporal dependency modeling, and a temporal convolutional network for sequence processing. The system processes patient EEG input by analyzing 40 channels from DEAP for multi-class emotion classification into four categories: HVHA (excited/happy), HVLA (calm/relaxed), LVHA (angry/nervous), and LVLA (sad/bored). The system operates by continuously monitoring the patient’s EEG signals and classifying their emotional state in real-time. The four-class output provides caregivers with granular information about both the valence (positive/negative) and arousal (activated/calm) dimensions of the patient’s emotional state. When negative emotions (LVHA or LVLA) are detected, the system alerts caregivers to provide appropriate emotional support and investigate potential sources of distress. This approach provides clinically actionable information to caregivers, enabling timely intervention and improved patient care tailored to the specific emotional state.
